{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3206a6",
   "metadata": {},
   "source": [
    "# Concept Network Tool\n",
    "\n",
    "It is recommended to run all code chunks in order.\n",
    "\n",
    "## Import data\n",
    "\n",
    "Here user has to define the following:\n",
    "\n",
    "- `DATA_PATH`: the folder including data files\n",
    "- `DATA_FILES` : automatically detected `csv` files from `DATA_PATH` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d8cccab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load R packages\n",
    "pacman::p_load(tidyverse, udpipe, stopwords, wordcloud, igraph, ggraph, textrank, textreuse, patchwork, RColorBrewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a31db1b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets in processed_data \n",
      " 1 \t processed_data/hs2014_processed.csv \n",
      " 2 \t processed_data/techeldercare_Q59_processed.csv \n",
      " 3 \t processed_data/techeldercare_Q62_processed.csv \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in eval(expr, envir, enclos):\n",
      "“NAs introduced by coercion”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): invalid 'description' argument\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): invalid 'description' argument\nTraceback:\n",
      "1. read.csv(df_path)",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "DATA_PATH <- \"processed_data\"\n",
    "DATA_FILES <- list.files(DATA_PATH, pattern = \".csv\",full.names = TRUE,)\n",
    "\n",
    "cat(\"Available datasets in\", DATA_PATH, \"\\n\",\n",
    "    \n",
    "    paste(paste(1:length(DATA_FILES) ,\"\\t\", DATA_FILES, \"\\n\"), sep = \"\\n\"), \"\\n\")\n",
    "\n",
    "\n",
    "df_path <- DATA_FILES[as.numeric(readline(prompt=\"Select data: \"))]\n",
    "df_raw <- read.csv(df_path)\n",
    "\n",
    "cat(df_path, \"selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9307e1",
   "metadata": {},
   "source": [
    "## Stopword removal\n",
    "\n",
    "R package [`stopwords`](https://cran.r-project.org/web/packages/stopwords/readme/README.html) includes three Finnish stop word lists: \n",
    "\n",
    "    1. nltk\n",
    "    2. snowball\n",
    "    3. stopwords-iso\n",
    "\n",
    "\n",
    "Then filter the data by excluding words from the stop word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ff1ae",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sw_lists_available <- sort(stopwords_getsources()[unlist(lapply(stopwords_getsources(), function(x) ifelse(\"fi\" %in% stopwords_getlanguages(x), TRUE, FALSE)))])\n",
    "sw_lists <- c(lapply(sw_lists_available, function(y) stopwords(\"fi\", y)), list(NA))\n",
    "sw_list_sizes <- lapply(sw_lists, function(z) ifelse(length(z) > 1, length(z), 0))\n",
    "                \n",
    "sw_options <- c(paste(c(sw_lists_available, \"None\"), paste0(\"(\", sw_list_sizes, \" words)\")), \"Custom\")\n",
    "                        \n",
    "cat(\"Stopword lists available:\\n\",paste(paste(1:length(sw_options) ,\"\\t\", sw_options, \"\\n\"), sep = \"\\n\"), \"\\n\")\n",
    "\n",
    "sw_selection <- readline(prompt=\"Select stopword list: \")                        \n",
    "\n",
    "if(as.numeric(sw_selection) == length(sw_options)) {\n",
    "    custom_stopwords <- readline(prompt=\"List all stopwords. Separate with a comma.\\n\")\n",
    "    stopword_list <- trimws(stringr::str_split(custom_stopwords, \",\", simplify = TRUE), \"both\")\n",
    "    cat(length(stopword_list), \"stopwords saved.\")\n",
    "} else {\n",
    "    stopword_list <- sw_lists[[as.numeric(sw_selection)]]\n",
    "    cat(\"Stopwords:\\n\", paste(stopword_list, collapse = \", \"), sep =\"\")\n",
    "}\n",
    "\n",
    "# Remove all the stop words above from the data\n",
    "df <- df_raw %>%\n",
    "    mutate(lemma = str_replace(lemma, \"#\", \"\")) %>%\n",
    "    filter(!lemma %in% stopword_list) \n",
    "       \n",
    "# Vocabulary       \n",
    "vocab <- unique(df$lemma)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a7136",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb88ae86",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# seed number, used for network plot layouts\n",
    "seed_num <- 2022\n",
    "\n",
    "# relevant words by part of speech\n",
    "relevant_pos <- c(\"NOUN\", \"VERB\", \"ADJ\", \"ADV\")\n",
    "\n",
    "# minimum number of occurences\n",
    "min_occurences <- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cf9e1",
   "metadata": {},
   "source": [
    "# Data summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57823a73",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "words_table <-  df %>%\n",
    "    summarize(respondents = n_distinct(doc_id),\n",
    "        total_tokens = n(),\n",
    "        unique_words = length(unique(token)),\n",
    "        unique_lemmas = length(unique(lemma))) \n",
    "\n",
    "\n",
    "pos_table <-  df %>% \n",
    "    count(upos, sort = TRUE) %>%\n",
    "    pivot_wider(names_from = upos, values_from = n, values_fill = 0)\n",
    "\n",
    "\n",
    "words_table\n",
    "pos_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad8826",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "word_freqs <- df %>% \n",
    "  filter(dep_rel != \"punct\") %>%\n",
    "  count(lemma, sort = TRUE) %>%\n",
    "  slice_max(n, n = 20) %>%\n",
    "  mutate(lemma = reorder(lemma, n)) %>%\n",
    "  ggplot(aes(n, lemma)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL, title = \"20 Most Common Words\")\n",
    "\n",
    "bigram_freqs <- df %>%\n",
    "  filter(dep_rel != \"punct\") %>%\n",
    "   mutate(bigram = txt_nextgram(lemma, n = 2)) %>%\n",
    "  count(bigram, sort = TRUE) %>%\n",
    "  slice_max(n, n = 20) %>%\n",
    "  mutate(bigram = reorder(bigram, n)) %>%\n",
    "  ggplot(aes(n, bigram)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL, title = \"20 Most Common Bigrams\")\n",
    "\n",
    "  word_freqs + bigram_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659d650",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab177021",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud_data <- df %>% \n",
    "    filter(dep_rel != \"punct\") %>%\n",
    "    count(lemma, sort = TRUE) \n",
    "\n",
    "wordcloud(words = word_cloud_data$lemma, \n",
    "        freq = word_cloud_data$n,\n",
    "        max.words= 100,\n",
    "        random.order=FALSE,\n",
    "        rot.per=0.35,\n",
    "        colors=RColorBrewer::brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28eff6",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f00c86",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "find_concepts <- function(data, concept) {\n",
    "    \n",
    "    if(str_detect(concept, \",\")){\n",
    "        concept <- str_extract_all(concept, pattern = \"\\\\w+\") %>% \n",
    "        unlist()\n",
    "        \n",
    "        cat(\"Displaying results including following concepts:\", \"\\n\",\n",
    "            paste(paste(1:length(concept) ,\"\\t\", concept, \"\\n\"), sep = \"\\n\"), \"\\n\")\n",
    "    }\n",
    "    \n",
    "    concept_keywords <- data %>% \n",
    "        filter(word1 %in% concept)  %>%\n",
    "        pull(keyword)\n",
    "    \n",
    "    all_concepts <- data %>% \n",
    "        filter(keyword %in% concept_keywords)\n",
    "    \n",
    "    return(all_concepts)\n",
    "}\n",
    "\n",
    "get_edges <- function(data, concept, threshold = NULL) {\n",
    "    df <-  data %>%\n",
    "    find_concepts(concept = concept) %>%\n",
    "    select(word1, word2, freq) %>%\n",
    "    group_by(word1,word2) %>%\n",
    "    summarize(n = sum(freq), .groups = \"drop\") %>%\n",
    "    rename(from = word1,\n",
    "          to = word2)\n",
    "    \n",
    "    if(!is.null(threshold)) {\n",
    "        df <- df %>% filter(n >= threshold)\n",
    "    }\n",
    "    \n",
    "    return(df)\n",
    "} \n",
    "\n",
    "get_nodes <- function(data, vocab) {\n",
    "    df <- data %>% filter(lemma %in% vocab)\n",
    "    \n",
    "    return(df)\n",
    "}\n",
    "\n",
    "plot_graph <- function(edges, nodes, concepts, ...) {  \n",
    "    \n",
    "nodes <- nodes %>%\n",
    "    mutate(is_concept = factor(ifelse(lemma %in% concepts, 0, 1), levels = 0:1, labels = c(\"Concept word\", \"Regular word\")))\n",
    "\n",
    "p <- graph_from_data_frame(edges, directed = FALSE, vertices = nodes) %>%\n",
    "    ggraph(layout = \"kk\") +\n",
    "    geom_edge_link(aes(width = n, edge_alpha = n), edge_colour = \"lightblue\") +\n",
    "    geom_node_point(aes(size = pagerank)) +\n",
    "    geom_node_text(aes(label = name, col = is_concept), check_overlap = TRUE, repel = TRUE) +\n",
    "    scale_color_manual(\"\", values = c(\"Concept word\" = \"red\", \"Regular word\" = \"black\")) +\n",
    "    theme_graph() +\n",
    "    labs(\n",
    "        title = \"Textrank extracted keyword occurences\",\n",
    "        subtitle = \"Adjectives, Nouns, Verbs\",\n",
    "         ... ) +\n",
    "    theme(legend.position = \"right\")    \n",
    "\n",
    "return(p)\n",
    "}\n",
    "\n",
    "textrank_table <- function(x, n = 25) {\n",
    "    keyword_table <- x$keywords %>%\n",
    "    filter(ngram > 1 & freq > 1) %>%\n",
    "    slice_max(freq, n = n)\n",
    "    \n",
    "    return(keyword_table)\n",
    "}\n",
    "\n",
    "textrank_graph <- function(x, input_word, threshold) {\n",
    "   \n",
    "    keyword_data <- x$keywords %>% \n",
    "        filter(ngram > 1 & freq > 1) %>% \n",
    "        mutate(word2 = strsplit(keyword, \"-\")) %>% \n",
    "        unnest(word2) %>%\n",
    "        group_by(keyword) %>%\n",
    "        mutate(word1 = lag(word2)) %>%\n",
    "        relocate(word1, .before = word2) %>%\n",
    "        ungroup() %>%\n",
    "        filter(!is.na(word1))\n",
    "\n",
    "\n",
    "    textrank_data <- data.frame(pagerank = keyw$pagerank$vector) %>%\n",
    "        rownames_to_column(\"lemma\") \n",
    "\n",
    "\n",
    "    edges <- get_edges(keyword_data, concept = input_word, threshold = threshold)\n",
    "    keyword_vocab <- unique(c(edges$from, edges$to))\n",
    "    nodes <- get_nodes(textrank_data, vocab = keyword_vocab)    \n",
    "    plot_graph(edges, nodes, concepts = query_list, caption = paste(\"Min.\", threshold, \"occurences.\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9921d24",
   "metadata": {},
   "source": [
    "# Concept extraction\n",
    "\n",
    "Input words that represent the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e29571",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "query <- tolower(readline(prompt=\"Enter words (separated by a comma):\"))\n",
    "\n",
    "query_list <- str_extract_all(query, pattern = \"\\\\w+\") %>% unlist()\n",
    "\n",
    "set.seed(seed_num)\n",
    "\n",
    "while(TRUE) {\n",
    "   valid_words = query_list %in% vocab\n",
    "    \n",
    "    if(tolower(query) == \"c\"){\n",
    "        interactive_status <- FALSE\n",
    "        cat(\"Stopping.\")\n",
    "        break\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    if(any(valid_words != TRUE)){\n",
    "        \n",
    "        cat(\"Following words not found in vocabulary:\", paste(query_list[!valid_words], collapse = \", \"), \"\\n\")\n",
    "        flush.console()\n",
    "        \n",
    "        query <- tolower(readline(prompt=\"Re-enter words: (or C to stop)\"))\n",
    "        query_list <- str_extract_all(query, pattern = \"\\\\w+\") %>% unlist()\n",
    "        \n",
    "    } \n",
    "    \n",
    "    if(all(valid_words) == TRUE){\n",
    "        interactive_status <- TRUE\n",
    "        found_data = df %>% filter(lemma %in% query_list)\n",
    "        break\n",
    "    }\n",
    "\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc250c",
   "metadata": {},
   "source": [
    "# Keyword extractions\n",
    "\n",
    "## Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4ac1a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "keyw <- textrank_keywords(df$lemma, relevant = df$upos %in% relevant_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bb59c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "textrank_table(keyw, n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded275dd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "textrank_graph(keyw, input_word = query, threshold = min_occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ebe29",
   "metadata": {},
   "source": [
    "## Likey"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
