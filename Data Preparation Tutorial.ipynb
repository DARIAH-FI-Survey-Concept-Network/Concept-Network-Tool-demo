{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e123deb",
   "metadata": {},
   "source": [
    "# Concept Network Tool: Data Prepartion Tutorial\n",
    "\n",
    "In this notebook, we show how you can prepare your survey with open-ended questions to be used with Concept Network Tool. \n",
    "\n",
    "At the moment, preparing data requires few manual steps that have to be run externally, these steps include:\n",
    "\n",
    "1. Preprocessing – check that there are no empty strings or white space and your data is imported correctly to R.\n",
    "2. Text annotation – tokenize, split into sentences, tag, parse, lemmatize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f45af8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pacman::p_load(tidyverse, udpipe, stopwords) # load R packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead36ac",
   "metadata": {},
   "source": [
    "# Helsingin Sanomat Loneliness Survey 2014\n",
    "\n",
    "The following example data set is publicly available for research, teaching and study at the Finnish Social Science Data Archive (FSD). In order to run this notebook, you have to register and download the data. You will be asked to supply the purpose of data use for the download.\n",
    "\n",
    "\n",
    "Data Citation:\n",
    "\n",
    "- Saari, Juho (Tampere University) & Helsingin Sanomat & Kauhanen, Jussi (University of Eastern Finland) & Karhunen, Leila (University of Eastern Finland) & Lagus, Krista (Aalto University) & Kainulainen, Sakari (Diaconia University of Applied Sciences) & Pantzar, Mika (University of Helsinki) & Erola, Jani (University of Turku) & Junttila, Niina (University of Turku) & Müller, Kiti (Finnish Institute of Occupational Health) & Huhta, Jaana (Finnish Institute of Occupational Health): Helsingin Sanomat Loneliness Survey 2014 [dataset]. Version 1.0 (2020-09-01). Finnish Social Science Data Archive [distributor]. http://urn.fi/urn:nbn:fi:fsd:T-FSD3360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24887776",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Import original data file downloaded from Finnish Social Science Data Archive (FSD).\n",
    "- Process whitespace and empty strings.\n",
    "- Create an indicator to separate respondents who have replied to the (only) open-ended question.\n",
    "- Add columns for word and character counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498e1c9d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df.raw <- read.csv(\"data/daF3360.csv\", sep = \";\") %>%\n",
    "  mutate(q9 = trimws(q9)) %>% # remove white space\n",
    "  mutate_all(na_if, \"\") %>% # replace empty string with NA \n",
    "  mutate(grp = ifelse(!is.na(q9), \"Yes\", \"No\"), # add an indicator based on if the respondent replied to open-ended questions\n",
    "         n_words = str_count(q9, \"\\\\w+\"), # add word count columns\n",
    "         n_chars = nchar(q9)) # add character count column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ec5e6",
   "metadata": {},
   "source": [
    "## Lemmatization, morphological tagging and dependency parsing \n",
    "[Turku Neural Parser](https://turkunlp.org/Turku-neural-parser-pipeline/) can tokenize, split into sentences, tag, parse, lemmatize Finnish texts. Alternatively, UDPipe R package also includes two Finnish language parsers that you can use instead of Turku Neural Parser as well:\n",
    "\n",
    "- UD Finnish FTB - FinnTreeBank 1 based model\n",
    "- UD Finnish TDT - Turku Dependency Treebank (TDT) based mode\n",
    "\n",
    "\n",
    "All of the methods produced [CoNLL-U](https://universaldependencies.org/format.html) formatted output which is the format the Concept Network tool uses as input.\n",
    "\n",
    "Preparing survey data for Turku Neural Parser pipeline processing:\n",
    "- Export open-ended survey responses as text file (`txt`)\n",
    "- Add double line breaks (`\\n\\n`) so that each response is interpreted as a paragraph.\n",
    "- Use row number as identification variable (`conllu_id`) in order to link the parsed output back to survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6726cc7c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df.export <- df.raw %>%\n",
    "  select(fsd_id, q9) %>%\n",
    "  mutate(conllu_id = row_number()) # add paragraph_id for parsing\n",
    "\n",
    "# add double line breaks as then Neural Parser will consider each response as a paragraph\n",
    "writeLines(df.export$q9, \"text_data/hs2014_q9.txt\", sep = \"\\n\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb4aff",
   "metadata": {},
   "source": [
    "### Running Turku Neural Parser pipeline\n",
    "\n",
    "Resources, tutorials and documentation:\n",
    "- Neural Parser documentation: [Turku neural parser pipeline](https://turkunlp.org/Turku-neural-parser-pipeline/)\n",
    "- Running the parser in CSC server environments: [GPU-accelerated machine learning - Docs CSC](https://docs.csc.fi/support/tutorials/gpu-ml/#turku-neural-parser)\n",
    "- [UDPipe - Text Annotation with UDpipe modles](https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html) (with R)\n",
    "\n",
    "\n",
    "### Annotated output\n",
    "- After successfully running the parser, export the output file formatted in [CoNLL-U](https://universaldependencies.org/format.html) format back to R, using package [`udpipe`](https://cran.r-project.org/web/packages/udpipe/index.html).\n",
    "- Èdit `doc_id` to include the index from `paragraph_id` and reset `paragraph_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1494fc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df.annotated <- udpipe_read_conllu(\"text_data/hs2014_q9.conllu\") %>%\n",
    "  mutate(sentence_id = as.numeric(sentence_id),\n",
    "         doc_id = paste0(\"doc\", paragraph_id)) %>%\n",
    "  mutate(paragraph_id = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3115c7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set output path to export data\n",
    "output_dir = \"processed_data\" \n",
    "\n",
    "if (!dir.exists(output_dir)){\n",
    "    dir.create(output_dir)\n",
    "}\n",
    "\n",
    "write.csv(df.annotated, paste(output_dir, \"hs2014_processed.csv\" ,sep = \"/\"),row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
